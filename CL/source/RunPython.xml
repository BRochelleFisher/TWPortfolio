<?xml version="1.0" encoding="UTF-8"?>
<article version="5.2" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xila="http://www.w3.org/2001/XInclude/local-attributes"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:trans="http://docbook.org/ns/transclusion"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <info>
    <title>Creating the Word List</title>

    <!-- <author>
      <personname><firstname>Rochelle</firstname><surname>Fisher</surname></personname>
    </author> -->

    <!-- <pubdate>19 June 2025</pubdate> -->
  </info>

  <section>
    <title>Create and Run the Word Counter Python Script</title>

    <para>To create the dictionary, we start with the unique words used and how many times each word is used in our sample. This Python script will give us a file formatted for easy import to a spreadsheet.</para>
	<procedure>
		<title>To create and run the python script word_counter.py:</title>
	    <step><para>Save your aggregated sample as <filename>sampleAgg.txt</filename>.</para></step>
	    <step><para>Copy this script in a text editor.</para></step>
	    <step><para>In the same folder as <filename>sampleAgg.txt</filename>, save the file as <filename>word_counter.py</filename>.</para></step>
	    <step><para>Run the python script:</para> 
	        <para><command>python word_counter.py > dictionary.csv</command></para>
		</step>
		</procedure>
		<programlisting linenumbering="numbered" language="python">
import re
import sys
from collections import Counter

def analyze_document_frequency(filepath: str = "sampleAgg.txt"):
    """
    Analyzes a text document to count word frequency.

    This function reads a text file, converts its content to lowercase,
    extracts words between 4 and 15 characters long,
    and counts the occurrences of each extracted word. It prints
    the words sorted by frequency in descending order, then 
    alphabetically for ties.

    Args:
        filepath (str): The path to the input text file. 
        Defaults to "sampleAgg.txt".

    Returns:
        None: Prints the word frequencies to standard output. 
        Errors are printed to stderr.
    """
    try:
        # Open and read the document, converting content to lowercase.
        # 'utf-8' encoding is specified for broad compatibility.
        with open(filepath, 'r', encoding='utf-8') as document_file:
            text_string = document_file.read().lower()
    except FileNotFoundError:
        # Handle the case where the specified input file does not exist.
        print(f"Error: '{filepath}' not found.", file=sys.stderr)
        return
    except Exception as e:
        # Catch other general exceptions during file reading.
        print(f"Error while reading: {e}", file=sys.stderr)
        return

    # Use regular expression to find all words.
    # '\b' ensures whole words. '[a-z]{4,15}' matches lowercase
    # letters between 4 and 15 characters.
    match_pattern = re.findall(r'\b[a-z]{4,15}\b', text_string)

    # Count word occurrences using collections.
    # Counter for efficiency.
    word_counts = Counter(match_pattern)

    # Sort words: primary key is count (descending), 
    # secondary key is word (ascending).
    # Lambda function creates a tuple for sorting: 
    # (-count) for descending, then word for ascending.
    sorted_words = sorted(word_counts.items(), \ 
    key=lambda item: (-item[1], item[0]))

    print("Word Frequencies:")
    print("-----------------")
    # Iterate through the sorted words and 
    # print each word and its count, separated by a pipe.
    for word, count in sorted_words:
        print(f"{word} | {count}")

if __name__ == "__main__":
    # Make sure the function runs only when 
    # the script is executed directly, 
    # not when imported as a module.
    analyze_document_frequency()
		</programlisting>
		<para>Note on Code Source:  
		This code started with the python script in <emphasis>Alchemy of Tomes</emphasis> <citation>Fisher (2020)</citation>, which
		does not work in the latest Python versions. We used Gemini (Google AI) to update this script.</para>
		
	</section>
	<section>
	 <title>Create the Dictionary File</title>



  
   <para>With three small samples of cybersecurity documentation from different organizations, the Python script gave us 4755 unique words.
   Your sample will be much larger. Your goal is to create a cybersecurity dictionary of approximately 1,000 words. This does not include product names
   or company-specific words. </para>
   <para>Prerequisites: Run the Python script.</para>
   <para>Effort: Use the output file from the Python script to create the dictionary file. This will require approximately ten minutes.</para>
   <procedure><title>To create the dictionary file:</title>
       <step><para>Import the output file to a spreadsheet.</para>
			<para>We will use Google Sheets. You can use Microsoft Excel or 
		similar.
			</para>
			<para>Our Python script uses a pipe ( | ) as a delimiter between the word and its frequency of use. When you import the file, set the pipe as the delimiter.
			</para>
		</step>
       <step><para>Set the column headers.</para>
		<para>If you know that you will use a specific AI-driven tool, such as writer.com or jasper.ai, change the dictionary headers and values to work with the acquired tool.</para>
			
		<para>If you do not have a checker tool yet, change row 1 to be these headers: <literal>Word, Count, Part of Speech, Definition, Good Example, Bad Example, Allowed?, Audience, Alt1, Alt2</literal>.</para>
		</step>
       <step><para>If there are rows between the header row and the first word, delete them.</para></step>
       <step><para>In a separate tab, enter your audience personas in one column. Make sure <literal>all</literal> is in this list.</para></step>
       <step><para>In the main tab, <guilabel>Audience</guilabel> column, set data validation to select the persona from the list.</para></step>
	</procedure>
	<para>The script sorted the output by highest frequency to lowest. Start with the words most used. These will be the easiest.</para></section>
</article>
		
	
